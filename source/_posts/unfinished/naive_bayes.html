<!doctype html>
<html>
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<style>
h1,
h2,
h3,
h4,
h5,
h6,
p,
blockquote {
    margin: 0;
    padding: 0;
}
body {
    font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", Arial, sans-serif;
    font-size: 13px;
    line-height: 18px;
    color: #737373;
    background-color: white;
    margin: 10px 13px 10px 13px;
}
table {
	margin: 10px 0 15px 0;
	border-collapse: collapse;
}
td,th {	
	border: 1px solid #ddd;
	padding: 3px 10px;
}
th {
	padding: 5px 10px;	
}

a {
    color: #0069d6;
}
a:hover {
    color: #0050a3;
    text-decoration: none;
}
a img {
    border: none;
}
p {
    margin-bottom: 9px;
}
h1,
h2,
h3,
h4,
h5,
h6 {
    color: #404040;
    line-height: 36px;
}
h1 {
    margin-bottom: 18px;
    font-size: 30px;
}
h2 {
    font-size: 24px;
}
h3 {
    font-size: 18px;
}
h4 {
    font-size: 16px;
}
h5 {
    font-size: 14px;
}
h6 {
    font-size: 13px;
}
hr {
    margin: 0 0 19px;
    border: 0;
    border-bottom: 1px solid #ccc;
}
blockquote {
    padding: 13px 13px 21px 15px;
    margin-bottom: 18px;
    font-family:georgia,serif;
    font-style: italic;
}
blockquote:before {
    content:"\201C";
    font-size:40px;
    margin-left:-10px;
    font-family:georgia,serif;
    color:#eee;
}
blockquote p {
    font-size: 14px;
    font-weight: 300;
    line-height: 18px;
    margin-bottom: 0;
    font-style: italic;
}
code, pre {
    font-family: Monaco, Andale Mono, Courier New, monospace;
}
code {
    background-color: #fee9cc;
    color: rgba(0, 0, 0, 0.75);
    padding: 1px 3px;
    font-size: 12px;
    -webkit-border-radius: 3px;
    -moz-border-radius: 3px;
    border-radius: 3px;
}
pre {
    display: block;
    padding: 14px;
    margin: 0 0 18px;
    line-height: 16px;
    font-size: 11px;
    border: 1px solid #d9d9d9;
    white-space: pre-wrap;
    word-wrap: break-word;
}
pre code {
    background-color: #fff;
    color:#737373;
    font-size: 11px;
    padding: 0;
}
@media screen and (min-width: 914px) {
    body {
        width: 854px;
        margin:10px auto;
    }
}
@media print {
	body,code,pre code,h1,h2,h3,h4,h5,h6 {
		color: black;
	}
	table, pre {
		page-break-inside: avoid;
	}
}
</style>
<title>朴素贝叶斯法</title>
<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax:{inlineMath:[['$$$','$$$']]}});</script><script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>
<body>
<h2>朴素贝叶斯法</h2>

<blockquote><p>  本文摘抄参考自：<a href="http://pan.baidu.com/share/link?shareid=2848109060&amp;uk=2184178031">李航-统计学习方法</a></p></blockquote>

<h3>1 朴素贝叶斯法</h3>

<ol>
<li>朴素贝叶斯法是典型的生成学习方法. 生成方法由训练数据学习联合概率分布<em>P(Y|X)</em>, 然后求得后验概率分布<em>P(Y|X)</em>. 具体来说，利用训练数据学习<em>P(Y|X)</em>和<em>P(Y)</em>的估计，得到联合概率分布:
 $$P\left( X,Y \right) =P\left( Y \right) P\left( { X }|{ Y } \right)$$</li>
<li><p>朴素贝叶斯法的基本假设是条件独立性，</p>

<p> $$P\left( { X=x }|{ Y=c_k } \right) =P\left( { { X }^{ \left( 1 \right)  }={ x }^{ \left( 1 \right)  },{ X }^{ \left( 2 \right)  }={ x }^{ \left( 2 \right)  },\cdots, { X }^{ \left( n \right)  }={ x }^{ \left( n \right)  } }|{ { Y=c_k } } \right)$$
 $$=\overset { n }{ \underset { j=1 }{ \prod  }  } P\left( { { X }^{ \left( j \right)  }={ x }^{ \left( j \right)  } }|{ Y=c_k } \right)$$</p></li>
</ol>


<blockquote><p>  朴素贝叶斯法中假设输入变量都是条件独立的，如果假设它们之间存在概率依存关系，模型就变成了贝叶斯网络，参见文献[Bishop C. Pattern Recognition and Machine Learning, Springer, 2006] <a href="http://pan.baidu.com/share/link?shareid=2811968744&amp;uk=2184178031">[pdf]</a></p></blockquote>

<ol>
<li><p>朴素贝叶斯法利用贝叶斯定理与学到的联合概率模型进行分类预测.
 $$P(Y|X)=\frac { P(X|Y) }{ P(X) } =\frac { P(Y)P(X|Y) }{ \sum _{ Y }^{  }{ P(Y)P(X|Y) }  }$$</p>

<p> 将输入x分到后验概率最大的类y.</p>

<p> $$y=arg{\max_{c_k}} P(Y=c_k) \overset { n }{ \underset { j=1 }{ \prod  }  } P\left( { { X^{(j)} }={ x }^{ \left( j \right)  } }|{ Y=c_k} \right)$$</p></li>
</ol>


<h3>2 朴素贝叶斯法的参数估计</h3>

<h4>2.1 极大似然估计</h4>

<p>先验概率<em>P(Y=c<sub>k</sub>)</em>的极大似然估计是</p>

<p>$$P(Y=c_k)=\frac {\sum_{i=1}^{N}I(y_i=c_k)}{N}, k=1,2,\cdots,K$$</p>

<p>设第<em>j</em>个特征<em>x<sup>(j)</sup></em>可能取值的集合为{<em>a<sub>j1</sub>,a<sub>j2</sub>,…,a<sub>jS<sub>j</sub></sub></em>}，条件概率<em>P(X<sup>(j)</sup>=a<sub>jl</sub>|Y=c<sub>k</sub>)</em>的极大似然估计是</p>

<center><img src="/Users/ting/workspace/equations/bayes_likelihood_maximization.png" /></center>


<p>$$j=1,2,\cdots,n; l=1,2,\cdots,S_j; k=1,2,\cdots,K$$</p>

<p>式中，x<sub>i</sub><sup>(j)</sup>是第<em>i</em>个样本的第<em>j</em>个特征；<em>a<sub>jl</sub></em>是第<em>j</em>个特征可能取的第<em>l</em>个值；<em>I</em>为指示函数.</p>

<h4>2.2 贝叶斯估计</h4>

<p>用极大似然估计可能会出现所要估计得概率值为0的情况，会影响后验概率的计算结果，使分类产生偏差。解决方法是引入常量$\lambda$>=0. 等于0时为极大似然估计，常取1，这时称为拉普拉斯平滑（Laplace smoothing）.</p>

<p>先验概率的贝叶斯估计是</p>

<p>$$\underset{\lambda}P(Y=c_k)=\frac {\sum_{i=1}^{N}I(y_i=c_k)+\lambda}{N+K\lambda}$$</p>

<p>条件概率的贝叶斯估计是</p>

<center><img src="/Users/ting/workspace/equations/bayes_estimation.png" /></center>



</body>
</html>